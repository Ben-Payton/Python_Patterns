{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Run this code block to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = pd.DataFrame({\n",
    "    \"reaction\":[\"rct1\",\"rct2\",\"rct3\",\"rct4\",\"rct5\"],\n",
    "    \"delta_G(kcal/mol)\":[-41.22,-33.10,10.111,-31.4152,-8.111],\n",
    "    \"Scientist_name\":[\"Ben\",\"Ben\",\"Steven\",\"Ben\",\"Steven\"]\n",
    "})\n",
    "x.to_csv(\"reaction_data.csv\")\n",
    "\n",
    "def gen_rand_file(file_number:int):\n",
    "    file_name = \"large_data\"+str(file_number)+\".txt\"\n",
    "    x = np.random.randint(1,1000001,10000)\n",
    "    x = list(x)\n",
    "    x = [str(i)+\"\\n\" for i in x]\n",
    "    with open(file_name,\"w\") as file:\n",
    "        file.writelines(x)\n",
    "\n",
    "for i in range(1,11):\n",
    "    gen_rand_file(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loops\n",
    "\n",
    "you can recognize when you need a loop when you want to perform the same action a certain number of times on some set of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for loops are good when you want to complete a task and you know exactly how many times. For example lets say we wanted to print a list of 5 file versions. We could write the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name_V1.txt\n",
      "file_name_V2.txt\n",
      "file_name_V3.txt\n",
      "file_name_V4.txt\n",
      "file_name_V5.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"file_name_V1.txt\")\n",
    "print(\"file_name_V2.txt\")\n",
    "print(\"file_name_V3.txt\")\n",
    "print(\"file_name_V4.txt\")\n",
    "print(\"file_name_V5.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't terrible, but it wouldn't scale very well and we could recognize the pattern and do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name_V1.txt\n",
      "file_name_V2.txt\n",
      "file_name_V3.txt\n",
      "file_name_V4.txt\n",
      "file_name_V5.txt\n",
      "file_name_V6.txt\n",
      "file_name_V7.txt\n",
      "file_name_V8.txt\n",
      "file_name_V9.txt\n",
      "file_name_V10.txt\n"
     ]
    }
   ],
   "source": [
    "MIN = 1\n",
    "MAX = 10\n",
    "for i in range(MIN,MAX+1):\n",
    "    print(\"file_name_V\"+str(i)+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only is this less lines of code for more results we can easily change min and max later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for loops are also good when you want to itterate through something of a fixed length. Below is an example set of numbers. Lets pretend these are temperatures of a system in units kelvin and we want to print them in units Celsius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement 1: 8986.02 C\n",
      "measurement 2: 432.94000000000005 C\n",
      "measurement 3: 2245.16 C\n",
      "measurement 4: 6556.29 C\n"
     ]
    }
   ],
   "source": [
    "numbers  = [9259.17, 706.09, 2518.31, 6829.44, 4464.02, 697.74, 8215.01]\n",
    "\n",
    "print(\"measurement 1:\",numbers[0]-273.15,\"C\")\n",
    "print(\"measurement 2:\",numbers[1]-273.15,\"C\")\n",
    "print(\"measurement 3:\",numbers[2]-273.15,\"C\")\n",
    "print(\"measurement 4:\",numbers[3]-273.15,\"C\")\n",
    "# and then the rest of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this works but it doesn't scale very well and you risk mistyping a conversion or having to hunt a typo to get syntax correct. Lets try again with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement 1: 8986.02 C\n",
      "measurement 2: 432.94 C\n",
      "measurement 3: 2245.16 C\n",
      "measurement 4: 6556.29 C\n",
      "measurement 5: 4190.87 C\n",
      "measurement 6: 424.59 C\n",
      "measurement 7: 7941.86 C\n"
     ]
    }
   ],
   "source": [
    "numbers  = [9259.17, 706.09, 2518.31, 6829.44, 4464.02, 697.74, 8215.01]\n",
    "\n",
    "# I'm doing some slightly fancy stuff with a formattable string here. You can acheive the output format you want\n",
    "# many different ways, but thought I might introduce it here.\n",
    "template_string = \"measurement {i}: {v:.2f} C\"\n",
    "for index, value in enumerate(numbers):\n",
    "    formatted_string = template_string.format(i=index+1,v=value-273.15)\n",
    "    print(formatted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common that we have large sets of data. Lets say Shubham sends you a file titled \"large_data1.txt\" (you can see it here in this folder.) He says \"hey can you let me know how many times a number less than 532 inclussive occurs in this data? THANKS!\". This file is 10,000 data points long. going through it manually would be awful. luckily this is a short for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "large_data1.txt contains 8 intigers less than 532."
     ]
    }
   ],
   "source": [
    "cutoff = 532\n",
    "\n",
    "# Here I am opening the file and then storing the contents in a list.\n",
    "with open(\"large_data1.txt\") as file:\n",
    "    large_data = file.readlines()\n",
    "\n",
    "# this uses list processing to make sure the items are intigers, not strings\n",
    "large_data = [int(i) for i in large_data]\n",
    "\n",
    "# we need something to count instances\n",
    "counter = 0\n",
    "\n",
    "# finally the loop\n",
    "\n",
    "for i in large_data:\n",
    "    if i <=cutoff:\n",
    "        counter = counter +1\n",
    "\n",
    "\n",
    "# print out our result\n",
    "print(counter)\n",
    "\n",
    "# maybe even format it nicely\n",
    "print(\"large_data1.txt contains\", counter, \"intigers less than\", cutoff ,end=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great code, but lets say you need to write is multiple times. You keep performing this same task everywhere in your code. It would be nice if you could write it once and then never have to think about it again or if it wasn't working then you need want to just have to fix it in one spot. You are describing a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take our last example where we counter instances of a number less than a cutoff in a large dataset. What if shubham gave us more data, or changed his mind about what number was the cutoff. It sould be nice to not have to go back and remember how our code works or have to find the spots to edit. Lets write a function that takes a file name and a cutoff and returns the number of instances less than that cuttoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the keyword `def` to specify a function\n",
    "# our function names follow variable name rules.\n",
    "# immediately after the function is parentheses, in those parenteses we specify arguments.\n",
    "# in out problem statement we know we will take a file_name and a cutoff.\n",
    "def less_than_cutoff(file_name,cutoff):\n",
    "    counter = 0\n",
    "    # all this code should look very similar from before but we are using the arguments that will be passed in as variables in this scope\n",
    "    with open(file_name,\"r\") as file:\n",
    "        large_data = file.readlines()\n",
    "    large_data = [int(i) for i in large_data]\n",
    "\n",
    "    for i in large_data:\n",
    "        if i <= cutoff:\n",
    "            counter = counter +1\n",
    "\n",
    "    # Here we use the return keyword to specify what the function will output. I want my output to be a generally usable as ppossible.\n",
    "    return counter\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply call our function on a data set and set the cutoff and get back to Shubham very quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(less_than_cutoff(\"large_data1.txt\",532))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions can actually be called inside other functions. This is why we wanted our output to be general earlier. we can make a function that returns a string output to out liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_ltc(file_name,cutoff):\n",
    "    occurences = less_than_cutoff(file_name,cutoff)\n",
    "\n",
    "    return f\"{file_name} contains {occurences} intigers less than or equal to {cutoff}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets use our new report ltc function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large_data6.txt contains 301 intigers less than or equal to 32345.\n"
     ]
    }
   ],
   "source": [
    "print(report_ltc(\"large_data6.txt\",32345))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretty nifty, now lets see if we can loop through all the files using the glob package and get reports for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large_data3.txt contains 4957 intigers less than or equal to 495837.\n",
      "large_data9.txt contains 5010 intigers less than or equal to 495837.\n",
      "large_data5.txt contains 5024 intigers less than or equal to 495837.\n",
      "large_data4.txt contains 4971 intigers less than or equal to 495837.\n",
      "large_data6.txt contains 4970 intigers less than or equal to 495837.\n",
      "large_data1.txt contains 4975 intigers less than or equal to 495837.\n",
      "large_data7.txt contains 4917 intigers less than or equal to 495837.\n",
      "large_data2.txt contains 5025 intigers less than or equal to 495837.\n",
      "large_data8.txt contains 5018 intigers less than or equal to 495837.\n",
      "large_data10.txt contains 4979 intigers less than or equal to 495837.\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"*.txt\"):\n",
    "    print(report_ltc(file,495837))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are a little uncomfortable with glob here is what something without it might look like in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large_data1.txt contains 2081 intigers less than or equal to 209384.\n",
      "large_data2.txt contains 2083 intigers less than or equal to 209384.\n",
      "large_data3.txt contains 2081 intigers less than or equal to 209384.\n",
      "large_data4.txt contains 2093 intigers less than or equal to 209384.\n",
      "large_data5.txt contains 2135 intigers less than or equal to 209384.\n",
      "large_data6.txt contains 2059 intigers less than or equal to 209384.\n",
      "large_data7.txt contains 2046 intigers less than or equal to 209384.\n",
      "large_data8.txt contains 2158 intigers less than or equal to 209384.\n",
      "large_data9.txt contains 2119 intigers less than or equal to 209384.\n",
      "large_data10.txt contains 2085 intigers less than or equal to 209384.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    file_name = \"large_data\" + str(i) + \".txt\"\n",
    "    print(report_ltc(file_name,209384))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
